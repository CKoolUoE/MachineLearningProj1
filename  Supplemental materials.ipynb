{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional libraries or submodules below\n",
    "\n",
    "# Display plots inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting defaults\n",
    "plt.rcParams['figure.figsize'] = (8,5)\n",
    "plt.rcParams['figure.dpi'] = 80\n",
    "\n",
    "# sklearn modules\n",
    "import sklearn\n",
    "\n",
    "# packages for the different models\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, KBinsDiscretizer\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, RidgeCV, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"sales.csv\")\n",
    "sales_test = pd.read_csv(\"sales_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(sales):\n",
    "    \"\"\"\n",
    "    Takes in dataframe sales, does the preprocessing and outputs\n",
    "    the featues we want to model as dataframe X.\n",
    "    \"\"\"\n",
    "    # Bin the neighorhoods in groups of 6\n",
    "    bin1 = ['nb_02', 'nb_09', 'nb_06', 'nb_13', 'nb_23', 'nb_01']\n",
    "    bin2 = ['nb_11', 'nb_17', 'nb_18', 'nb_07', 'nb_20', 'nb_22']\n",
    "    bin3 = ['nb_24', 'nb_04', 'nb_08', 'nb_14', 'nb_05', 'nb_16']\n",
    "    bin4 = ['nb_21', 'nb_15', 'nb_10', 'nb_12', 'nb_03', 'nb_19']\n",
    "    \n",
    "    # Create 4 new features: neighborhood groups with an increasing mean\n",
    "    sales['nbh_1'] = sales['neighborhood'].isin(bin1).astype(int)\n",
    "    sales['nbh_2'] = sales['neighborhood'].isin(bin2).astype(int)\n",
    "    sales['nbh_3'] = sales['neighborhood'].isin(bin3).astype(int)\n",
    "    sales['nbh_4'] = sales['neighborhood'].isin(bin4).astype(int)\n",
    "\n",
    "    # Combine year_sold and year_built into 1 column age\n",
    "    sales['age'] = sales['year_sold'] - sales['year_built']\n",
    "    \n",
    "    # log transform sale_price and lot_area\n",
    "    sales[\"log_sale_price\"] = np.log(sales[\"sale_price\"])\n",
    "    sales[\"log_lot_area\"] = np.log(sales[\"lot_area\"])\n",
    "    \n",
    "    # Create dataframe X and drop all the features we do not want in our model\n",
    "    X = sales.copy()\n",
    "    X = X.drop(columns = [\"sale_price\", \"log_sale_price\", \"garage_area\", \"year_sold\", \n",
    "                          \"year_built\", \"neighborhood\", \"lot_area\", \"full_bath\"])\n",
    "    \n",
    "    # Transform the categorical variables into dummys,\n",
    "    # to prevent rank deficiency we add drop_first = True\n",
    "    X = pd.get_dummies(X, drop_first = True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "X = preprocessing(sales)\n",
    "y = sales.log_sale_price\n",
    "\n",
    "# test data\n",
    "X_test = preprocessing(sales_test)\n",
    "y_test = sales_test.log_sale_price\n",
    "\n",
    "# Scaling the data\n",
    "X_merged = pd.concat([X, X_test])\n",
    "S = StandardScaler().fit(X_merged)\n",
    "\n",
    "X_scaled = S.transform(X)\n",
    "X_test_scaled = S.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with 2 helper functions\n",
    "def model_fit(m, X, y, plot = False):\n",
    "    \"\"\"Returns the root mean squared error of a fitted model based on provided X and y values.\n",
    "    \n",
    "    Args:\n",
    "        m: sklearn model object\n",
    "        X: model matrix to use for prediction\n",
    "        y: outcome vector to use to calculating rmse and residuals\n",
    "        plot: boolean value, should fit plots be shown \n",
    "    \"\"\"\n",
    "    \n",
    "    y_hat = m.predict(X)\n",
    "    rmse = mean_squared_error(y, y_hat, squared=False)\n",
    "    true_rmse = mean_squared_error(np.exp(y), np.exp(y_hat), squared=False)\n",
    "    \n",
    "    res = pd.DataFrame(\n",
    "        data = {'y': y, 'y_hat': y_hat, 'resid': y - y_hat}\n",
    "    )\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        plt.subplot(121)\n",
    "        sns.lineplot(x='x', y='y', color=\"grey\", data =  pd.DataFrame(data={'x': [min(y),max(y)], 'y': [min(y),max(y)]}))\n",
    "        sns.scatterplot(x='y', y='y_hat', data=res).set_title(\"Fit plot\")\n",
    "        \n",
    "        plt.subplot(122)\n",
    "        sns.scatterplot(x='y', y='resid', data=res).set_title(\"Residual plot\")\n",
    "        \n",
    "        plt.subplots_adjust(left=0.0)\n",
    "        \n",
    "        plt.suptitle(\"Model rmse = \" + str(round(rmse, 4)), fontsize=16)\n",
    "        plt.show()\n",
    "    \n",
    "    return rmse, true_rmse\n",
    "\n",
    "def get_coefs(m):\n",
    "    \"\"\"Returns the model coefficients from a Scikit-learn model object as an array,\n",
    "    includes the intercept if available.\n",
    "    \"\"\"\n",
    "    \n",
    "    if m.intercept_ is None:\n",
    "        return m.coef_\n",
    "    \n",
    "    return np.concatenate([[m.intercept_], m.coef_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for training set\n",
      "--------------------------------------\n",
      "RMSE is 0.11120661717953698\n",
      "\n",
      "\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 0.11211512775305356\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X, y)\n",
    "\n",
    "# model evaluation for trainig set\n",
    "lr_rmse = model_fit(lr, X, y, plot=False)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(lr_rmse[0]))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "lr_test_rmse = model_fit(lr, X_test, y_test, plot=False)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(lr_test_rmse[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for training set\n",
      "--------------------------------------\n",
      "RMSE is 0.08719255055352185\n",
      "max_depth is 9\n",
      "min_samples_leaf 2\n",
      "\n",
      "\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 0.15788808218082026\n"
     ]
    }
   ],
   "source": [
    "dt = GridSearchCV(\n",
    "     DecisionTreeRegressor(),\n",
    "     param_grid={\"max_depth\": range(1, 10),\n",
    "                 \"min_samples_leaf\": range(1, 10)},\n",
    "     cv=KFold(5, True, random_state=1234),\n",
    "    scoring=\"neg_root_mean_squared_error\"\n",
    ").fit(X, y)\n",
    "\n",
    "# model evaluation for training set\n",
    "dt_rmse = model_fit(dt, X, y, plot=False)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(dt_rmse[0]))\n",
    "print('max_depth is', dt.best_params_['max_depth'])\n",
    "print('min_samples_leaf', dt.best_params_['min_samples_leaf'])\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# model evaluation for testing set\n",
    "dt_test_rsme = model_fit(dt, X_test, y_test, plot=False)   \n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(dt_test_rsme[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for training set\n",
      "--------------------------------------\n",
      "RMSE is 0.11124306072835116\n",
      "The optimal alpha is 12.0\n",
      "\n",
      "\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 0.11213073528659062\n"
     ]
    }
   ],
   "source": [
    "r_cv = RidgeCV(\n",
    "    alphas = np.linspace(0.1, 20, num=200), # RidgeCV does not allow alpha=0 for some reason\n",
    "    scoring = \"neg_mean_squared_error\"\n",
    ").fit(X_scaled, y)\n",
    "\n",
    "# model evaluation for training set\n",
    "ridge_rmse = model_fit(r_cv, X_scaled, y, plot=False)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(ridge_rmse[0]))\n",
    "print(\"The optimal alpha is\", round(r_cv.alpha_, 1))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "\n",
    "ridge_test_rmse = model_fit(r_cv, X_test_scaled, y_test, plot = False)\n",
    "    \n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(ridge_test_rmse[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal alpha is 0.01\n",
      "The optimal gamma is 1.0\n"
     ]
    }
   ],
   "source": [
    "kr = GridSearchCV(KernelRidge(kernel='rbf'),\n",
    "                 param_grid={\"alpha\": np.logspace(-2, 0, num=4),\n",
    "                             \"gamma\": np.logspace(0, 3, num=50)},\n",
    "                 scoring = 'neg_mean_squared_error', cv=5)\n",
    "\n",
    "kr = kr.fit(X, y)\n",
    "rmse_kr = model_fit(kr, X, y, plot = False)\n",
    "\n",
    "rmse_test_kr = model_fit(kr, X_test, y_test, plot = False)\n",
    "\n",
    "print(\"The optimal alpha is\", kr.best_params_[\"alpha\"])\n",
    "print(\"The optimal gamma is\", kr.best_params_[\"gamma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for training set\n",
      "--------------------------------------\n",
      "RMSE is 0.1165383663639526\n",
      "\n",
      "\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 11.75296449421215\n"
     ]
    }
   ],
   "source": [
    "# model evaluation for training set\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_kr[0]))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_test_kr[0]))\n",
    "\n",
    "# overfitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for training set\n",
      "--------------------------------------\n",
      "The optimal alpha is 0.01\n",
      "RMSE is 0.11682673544441437\n",
      "\n",
      "\n",
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 0.1127330746826424\n"
     ]
    }
   ],
   "source": [
    "def optimal_alpha(x='x', y='y'):\n",
    "    alphas = np.linspace(0.01, 1, num=100)\n",
    "\n",
    "    l_gs = GridSearchCV(\n",
    "        Lasso(),\n",
    "        param_grid={'alpha': alphas},\n",
    "        cv=KFold(5, True, random_state=1234),\n",
    "        scoring=\"neg_root_mean_squared_error\"\n",
    "    ).fit(x, y)\n",
    "\n",
    "    l_cv_res = pd.DataFrame().assign(\n",
    "        alpha = alphas,\n",
    "        rmse = -1 * l_gs.cv_results_['mean_test_score'],           # mean of the rmse over the folds\n",
    "        rmse_se = l_gs.cv_results_['std_test_score'] / np.sqrt(l_gs.n_splits_), # standard error of the rmse\n",
    "    )\n",
    "\n",
    "    i = l_cv_res.rmse.idxmin()\n",
    "\n",
    "    min_rmse = l_cv_res.rmse[i]       # Smallest rmse\n",
    "    min_rmse_se = l_cv_res.rmse_se[i] # Std error of the smallest rmse\n",
    "\n",
    "    sub = l_cv_res.rmse <= min_rmse + min_rmse_se # Find rmses w/in 1se of the min + se\n",
    "\n",
    "    alpha_opt = l_cv_res.alpha[ sub ].max() # Find the largest alpha\n",
    "    return alpha_opt\n",
    "\n",
    "\n",
    "# model evaluation for training set\n",
    "alpha_opt = optimal_alpha(x=X_scaled, y=y)\n",
    "\n",
    "lasso = Lasso(alpha_opt).fit(X_scaled, y)\n",
    "rmse_lasso = model_fit(lasso, X_scaled, y, plot=False)\n",
    "\n",
    "print(\"The model performance for training set\")\n",
    "print(\"--------------------------------------\")\n",
    "print(\"The optimal alpha is\", alpha_opt)\n",
    "print('RMSE is {}'.format(rmse_lasso[0]))\n",
    "print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "lasso_test = Lasso(alpha_opt).fit(X_test_scaled, y_test)\n",
    "rmse_test_lasso = model_fit(lasso_test, X_test_scaled, y_test, plot=False)\n",
    "    \n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse_test_lasso[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
